{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff17a30",
   "metadata": {},
   "source": [
    "#### Steps -\n",
    "\n",
    "1. Install tabula from this path: https://tabula.technology/\n",
    "2. (optional) Install/get subscription for YNAB: https://www.youneedabudget.com/\n",
    "3. Create folder path like so:\n",
    "    \\root\\\n",
    "    \\root\\<year>\\1-tabula-output\\\n",
    "    \\root\\<year>\\2-cleaned\\\n",
    "    \\root\\<year>\\3-processed\\\n",
    "    \\root\\<year>\\4-ynab\\\n",
    "\n",
    "4. Download pdf statement and put in \\<year>\\0-pdf\\\n",
    "5. Open tabula, and generate csv, paste in \\<year>\\1-tabula-output\\\n",
    "6. Open file from step 2, and clean up as follows\n",
    "  - no header needed\n",
    "  - 6 columns: date, transaction type, payee, outflow, inflow, balance\n",
    "  - some columns may have shifted... adjust them\n",
    "  - sometimes strange characters in first row etc... remove them\n",
    "  - save file\n",
    "7. Open \\Balances.csv\n",
    "  - Confirm date column is yyyy-mm-dd\n",
    "  - Add new row for current month\n",
    "  - Populate opening, closing balance from pdf\n",
    "  - Drag-fill 'ThisMonth_Closing_NextMonth_Opening_Reconciled' for previous row and confirm it is TRUE\n",
    "8. Run jupyter notebook\n",
    "9. Populate 'Stmt_Balance_Notebook_Balance_Reconciled' if TRUE, if not investigate\n",
    "10. Load file from \\<year>\\4-ynab\\ into YNAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accessory-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54bb0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'D:\\\\MyDocuments\\\\Bank-Statements\\\\HSBC\\\\'\n",
    "root_path = root + '2022\\\\'\n",
    "tabula_path = root_path + '1-tabula-output\\\\'\n",
    "cleaned_path = root_path + '2-cleaned\\\\'\n",
    "processed_path = root_path + '3-processed\\\\'\n",
    "ynab_path = root_path + '4-ynab\\\\'\n",
    "balances_file = root + 'Balances.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f581d3",
   "metadata": {},
   "source": [
    "## Table of contents <a id=\"0\"></a>\n",
    "* [Generate list of files](#file-list)\n",
    "* [Cleanup dataset](#cleanup)\n",
    "* [Process dataset](#process)\n",
    "* [Validate dataset](#validate)\n",
    "* [Generate YNAB files](#ynab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01d638",
   "metadata": {},
   "source": [
    "### Generate list of files <a name=\"file-list\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "complicated-discovery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'statement_date': '2022-01-25',\n",
       "  'filename': '2022-01-25_Statement.csv',\n",
       "  'original_full_path': 'D:\\\\MyDocuments\\\\Bank-Statements\\\\HSBC\\\\2022\\\\1-tabula-output\\\\2022-01-25_Statement.csv'},\n",
       " {'statement_date': '2022-02-25',\n",
       "  'filename': '2022-02-25_Statement.csv',\n",
       "  'original_full_path': 'D:\\\\MyDocuments\\\\Bank-Statements\\\\HSBC\\\\2022\\\\1-tabula-output\\\\2022-02-25_Statement.csv'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [{'statement_date': f[0:10], 'filename': f, 'original_full_path': os.path.join(dp, f)}\n",
    "          for dp, dn, filenames in os.walk(tabula_path) \n",
    "          for f in filenames \n",
    "          if (os.path.splitext(f)[1] == '.csv') \n",
    "          and ('_processed' not in os.path.splitext(f)[0]) \n",
    "          and ('_ynab' not in os.path.splitext(f)[0])]\n",
    "\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddb5e6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92 entries, 0 to 91\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   stmt_date  92 non-null     datetime64[ns]\n",
      " 1   opening    92 non-null     float64       \n",
      " 2   closing    92 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(2)\n",
      "memory usage: 2.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_balances = pd.read_csv(balances_file)\n",
    "cols = ['stmt_date', 'opening', 'closing']\n",
    "df_balances.columns = cols\n",
    "df_balances = df_balances.astype({\"stmt_date\": 'datetime64'\n",
    "                                  ,\"opening\": 'float64'\n",
    "                                  ,\"closing\": 'float64'})\n",
    "df_balances.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bbd87d",
   "metadata": {},
   "source": [
    "### Clean up dataset <a name=\"cleanup\"></a>\n",
    "[Go back to top](#0)\n",
    "\n",
    "1. Add header rows\n",
    "2. Add date in all rows\n",
    "3. Combine multi-line payees\n",
    "4. Remove 'Balance carried forward', 'Balance brought forward' rows within dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f13f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df_param):\n",
    "    df = copy.deepcopy(df_param)\n",
    "    header_cols = ['date', 'transaction_type', 'payee', 'outflow', 'inflow', 'balance']\n",
    "    \n",
    "    # set columns\n",
    "    df.columns = header_cols\n",
    "    \n",
    "    # transform date\n",
    "    df[['payee', 'outflow', 'inflow', 'balance']] = df[['payee', 'outflow', 'inflow', 'balance']].astype(str)\n",
    "    df['date'] = pd.to_datetime(\n",
    "        df['date'].str[:2] \n",
    "        + '-' \n",
    "        + df['date'].str[3:6] \n",
    "        + '-' \n",
    "        + '20' + df['date'].str[-2:]\n",
    "    )\n",
    "    \n",
    "    # remove unneeded columns\n",
    "    cols = ['date', 'payee', 'outflow', 'inflow', 'balance']\n",
    "    df = df[cols]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # change data types\n",
    "    df.loc[:, 'balance'] = df['balance'].str.replace(',', '')\n",
    "    df.loc[:, 'outflow'] = df['outflow'].str.replace(',', '')\n",
    "    df.loc[:, 'inflow'] = df['inflow'].str.replace(',', '')\n",
    "    df.loc[df['outflow'] == '.', 'outflow'] = 0.0\n",
    "    df = df.astype({'outflow': float, 'inflow': float, 'balance': float})\n",
    "    \n",
    "    df['outflow'].fillna(0, inplace=True)\n",
    "    df['inflow'].fillna(0, inplace=True)\n",
    "    df['balance'].fillna(0, inplace=True)\n",
    "    \n",
    "    # remove balance carried forward rows within dataset\n",
    "    df_temp = df.iloc[1:-1, :]\n",
    "    idx = df_temp.loc[df_temp['payee'].str.contains('(?i)balance'), :].index\n",
    "    df.drop(idx, inplace=True)\n",
    "    \n",
    "    # combine multi-line payees\n",
    "    for idx, row in df.iterrows():\n",
    "        if ((df.loc[idx, 'outflow']==0.0) and (df.loc[idx, 'inflow']==0.0) and (df.loc[idx, 'balance']==0.0)):\n",
    "            df.loc[idx+1, 'payee'] = df.loc[idx, 'payee'] + ' ' + df.loc[idx+1, 'payee']\n",
    "            df.loc[idx+1, 'date'] = df.loc[idx, 'date']\n",
    "    \n",
    "    df.drop(df[(df['outflow']==0.0) & (df['inflow']==0.0) & (df['balance']==0.0)].index, inplace=True)\n",
    "    df['date'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f7edb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up file: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\1-tabula-output\\2022-01-25_Statement.csv]\n",
      "Cleaning up complete: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\2-cleaned\\2022-01-25_Statement_cleaned.csv]\n",
      "Cleaning up file: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\1-tabula-output\\2022-02-25_Statement.csv]\n",
      "Cleaning up complete: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\2-cleaned\\2022-02-25_Statement_cleaned.csv]\n"
     ]
    }
   ],
   "source": [
    "# clean up files\n",
    "for file in result:\n",
    "    original_full_path = file['original_full_path']\n",
    "    print('Cleaning up file: [{filename}]'.format(filename=original_full_path))\n",
    "    df_in = pd.read_csv(original_full_path, header=None)\n",
    "    df = clean_df(df_in)\n",
    "    file_name = os.path.basename(original_full_path)\n",
    "    cleaned_df_filename = os.path.splitext(file_name)[0] + '_cleaned.csv'\n",
    "    cleaned_df_full_path = os.path.join(cleaned_path, cleaned_df_filename)\n",
    "    file['cleaned_full_path'] = cleaned_df_full_path\n",
    "    df.to_csv(cleaned_df_full_path, index=False)\n",
    "    print('Cleaning up complete: [{filename}]'.format(filename=cleaned_df_full_path))\n",
    "\n",
    "cleaned_result = [os.path.join(dp, f)\n",
    "                  for dp, dn, filenames in os.walk(cleaned_path) \n",
    "                  for f in filenames \n",
    "                  if (os.path.splitext(f)[1] == '.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95641110",
   "metadata": {},
   "source": [
    "### Process cleaned up files <a name=\"process\"></a>\n",
    "[Go back to top](#0)\n",
    "\n",
    "Combine outflow and inflow amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d06b0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df_param):\n",
    "    df = copy.deepcopy(df_param)\n",
    "    \n",
    "    # combine outflow and inflow into single amount column\n",
    "    df.loc[:, 'outflow'] = (df['outflow']*-1) + df['inflow']\n",
    "    df = df.rename(columns={'outflow': 'amount'})\n",
    "    df.drop(df[(df['amount']==0.0) & (df['balance']==0.0)].index, inplace=True)\n",
    "    df['date'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    cols = ['date', 'payee', 'amount', 'balance']\n",
    "    \n",
    "\n",
    "    df = df[cols]\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d455bfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\2-cleaned\\2022-01-25_Statement_cleaned.csv]\n",
      "Processing complete: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\3-processed\\2022-01-25_Statement_cleaned_processed.csv]\n",
      "Processing file: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\2-cleaned\\2022-02-25_Statement_cleaned.csv]\n",
      "Processing complete: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\3-processed\\2022-02-25_Statement_cleaned_processed.csv]\n"
     ]
    }
   ],
   "source": [
    "# process files\n",
    "for file in result:\n",
    "    cleaned_full_path = file['cleaned_full_path']\n",
    "    \n",
    "    print('Processing file: [{filename}]'.format(filename=cleaned_full_path))\n",
    "    df_in = pd.read_csv(cleaned_full_path)\n",
    "    df = process_df(df_in)\n",
    "    file_name = os.path.basename(cleaned_full_path)\n",
    "    processed_df_filename = os.path.splitext(file_name)[0] + '_processed.csv'\n",
    "    processed_df_full_path = os.path.join(processed_path, processed_df_filename)\n",
    "    \n",
    "    file['processed_full_path'] = processed_df_full_path\n",
    "    \n",
    "    df.to_csv(processed_df_full_path, index=False)\n",
    "    print('Processing complete: [{filename}]'.format(filename=processed_df_full_path))\n",
    "\n",
    "processed_result = [os.path.join(dp, f)\n",
    "                  for dp, dn, filenames in os.walk(processed_path) \n",
    "                  for f in filenames \n",
    "                  if (os.path.splitext(f)[1] == '.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0bb12",
   "metadata": {},
   "source": [
    "### Validate processed files <a name=\"validate\"></a>\n",
    "[Go back to top](#0)\n",
    "\n",
    "Validate opening and closing balance amount with statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "artificial-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_df(df_param):\n",
    "    df = copy.deepcopy(df_param)\n",
    "    \n",
    "    # validate transactions, by comparing balances\n",
    "    opening_balance = df.loc[df['payee'].str.upper() == 'BALANCE BROUGHT FORWARD', 'balance'].values[0]\n",
    "    \n",
    "    df = df.loc[(df['payee'].str.upper() != 'BALANCE BROUGHT FORWARD') \n",
    "                & (df['payee'].str.upper() != 'BALANCE CARRIED FORWARD'), :]\n",
    "    \n",
    "    df_datewise = df.groupby('date').sum(['amount', 'balance'])\n",
    "    df_datewise.reset_index(inplace=True)\n",
    "    for idx, row in df_datewise.iterrows():\n",
    "        if idx <= len(df_datewise.index) - 2: \n",
    "            df_datewise.loc[idx+1, 'calculated_balance'] = df_datewise.loc[idx, 'balance'] + df_datewise.loc[idx+1, 'amount']\n",
    "    \n",
    "    closing_balance = df_datewise.loc[len(df_datewise.index)-1, 'calculated_balance']\n",
    "    \n",
    "    return opening_balance, closing_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "southern-orange",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating file: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\3-processed\\2022-01-25_Statement_cleaned_processed.csv]\n",
      "Validating file: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\3-processed\\2022-02-25_Statement_cleaned_processed.csv]\n"
     ]
    }
   ],
   "source": [
    "# validate files\n",
    "for file in result:\n",
    "    processed_full_path = file['processed_full_path']\n",
    "    \n",
    "    print('Validating file: [{filename}]'.format(filename=processed_full_path))\n",
    "    df_in = pd.read_csv(processed_full_path)\n",
    "    opening_balance, closing_balance = validate_df(df_in)\n",
    "    \n",
    "    file['opening'] = opening_balance\n",
    "    file['closing'] = closing_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89ba364d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stmt_date</th>\n",
       "      <th>opening</th>\n",
       "      <th>closing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-07-25</td>\n",
       "      <td>21274.59</td>\n",
       "      <td>23052.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-25</td>\n",
       "      <td>23052.24</td>\n",
       "      <td>24671.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-25</td>\n",
       "      <td>24671.14</td>\n",
       "      <td>26486.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-10-25</td>\n",
       "      <td>26486.91</td>\n",
       "      <td>28131.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-11-25</td>\n",
       "      <td>28131.31</td>\n",
       "      <td>26351.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stmt_date   opening   closing\n",
       "0 2014-07-25  21274.59  23052.24\n",
       "1 2014-08-25  23052.24  24671.14\n",
       "2 2014-09-25  24671.14  26486.91\n",
       "3 2014-10-25  26486.91  28131.31\n",
       "4 2014-11-25  28131.31  26351.06"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7acacb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement_date</th>\n",
       "      <th>filename</th>\n",
       "      <th>original_full_path</th>\n",
       "      <th>cleaned_full_path</th>\n",
       "      <th>processed_full_path</th>\n",
       "      <th>opening</th>\n",
       "      <th>closing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>2022-01-25_Statement.csv</td>\n",
       "      <td>D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\1-tab...</td>\n",
       "      <td>D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\2-cle...</td>\n",
       "      <td>D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\3-pro...</td>\n",
       "      <td>9646.72</td>\n",
       "      <td>11383.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>2022-02-25_Statement.csv</td>\n",
       "      <td>D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\1-tab...</td>\n",
       "      <td>D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\2-cle...</td>\n",
       "      <td>D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\3-pro...</td>\n",
       "      <td>11383.30</td>\n",
       "      <td>12532.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  statement_date                  filename  \\\n",
       "0     2022-01-25  2022-01-25_Statement.csv   \n",
       "1     2022-02-25  2022-02-25_Statement.csv   \n",
       "\n",
       "                                  original_full_path  \\\n",
       "0  D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\1-tab...   \n",
       "1  D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\1-tab...   \n",
       "\n",
       "                                   cleaned_full_path  \\\n",
       "0  D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\2-cle...   \n",
       "1  D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\2-cle...   \n",
       "\n",
       "                                 processed_full_path   opening   closing  \n",
       "0  D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\3-pro...   9646.72  11383.30  \n",
       "1  D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\3-pro...  11383.30  12532.55  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame.from_records(result)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af6c464e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stmt_date</th>\n",
       "      <th>opening_calc</th>\n",
       "      <th>closing_calc</th>\n",
       "      <th>opening_stmt</th>\n",
       "      <th>closing_stmt</th>\n",
       "      <th>prev_closing</th>\n",
       "      <th>balances_valid</th>\n",
       "      <th>opening_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>9646.72</td>\n",
       "      <td>11383.30</td>\n",
       "      <td>9646.72</td>\n",
       "      <td>11383.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>11383.30</td>\n",
       "      <td>12532.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11383.3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stmt_date  opening_calc  closing_calc  opening_stmt  closing_stmt  \\\n",
       "0 2022-01-25       9646.72      11383.30       9646.72       11383.3   \n",
       "1 2022-02-25      11383.30      12532.55           NaN           NaN   \n",
       "\n",
       "   prev_closing  balances_valid  opening_valid  \n",
       "0           NaN            True          False  \n",
       "1       11383.3           False           True  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['statement_date', 'opening', 'closing']\n",
    "df_result = df_result[cols]\n",
    "cols = ['stmt_date', 'opening', 'closing']\n",
    "df_result.columns = cols\n",
    "df_result = df_result.astype({'stmt_date': 'datetime64'})\n",
    "df_result = pd.merge(df_result, df_balances, how='left', on='stmt_date', suffixes=['_calc', '_stmt'])\n",
    "df_result['prev_closing'] = df_result['closing_calc'].shift(1)\n",
    "\n",
    "df_result['balances_valid'] = pd.Series((round(df_result['opening_calc'], 2) == round(df_result['opening_stmt'], 2)) \n",
    "                               & (round(df_result['closing_calc'], 2) == round(df_result['closing_stmt'], 2)))\n",
    "\n",
    "df_result['opening_valid'] = pd.Series((round(df_result['prev_closing'], 2) == round(df_result['opening_calc'], 2)))\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1f2a3e",
   "metadata": {},
   "source": [
    "### Genarate YNAB files <a name=\"ynab\"></a>\n",
    "[Go back to top](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "prompt-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_payee(in_str: str):\n",
    "    out_str = in_str\n",
    "    category = \"\"\n",
    "    mapping = [{\"str\": 'asda', 'repl': 'Asda', 'category': 'Monthly recurring: Groceries'}\n",
    "               , {\"str\": 'tesco', 'repl': 'Tesco', 'category': 'Monthly recurring: Groceries'}\n",
    "               , {\"str\": 'sainsburys', 'repl': 'Sainsburys', 'category': 'Monthly recurring: Groceries'}\n",
    "               , {\"str\": 'morrisons', 'repl': 'Morrisons', 'category': 'Monthly recurring: Groceries'}\n",
    "               , {\"str\": 'taj stores', 'repl': 'Taj Stores', 'category': 'Monthly recurring: Groceries'}\n",
    "               , {\"str\": 'waitrose', 'repl': 'Waitrose', 'category': 'Monthly recurring: Groceries'}\n",
    "               \n",
    "               , {\"str\": 'ee limited', 'repl': 'EE Limited', 'category': 'Monthly recurring: Phone'}\n",
    "               , {\"str\": 'the gym ltd', 'repl': 'The Gym Ltd', 'category': 'Monthly recurring: Gym'}\n",
    "               , {\"str\": 'lul ticket', 'repl': 'TFL', 'category': 'Monthly recurring: Transport'}\n",
    "               , {\"str\": 'oyster', 'repl': 'TFL', 'category': 'Monthly recurring: Transport'}\n",
    "               , {\"str\": 'igloo energy', 'repl': 'Igloo', 'category': 'Monthly recurring: Gas and electric'}\n",
    "               , {\"str\": 'virgin media', 'repl': 'Virgin Media', 'category': 'Monthly recurring: Internet'}\n",
    "               \n",
    "               , {\"str\": 'dominos', 'repl': 'Dominos', 'category': 'Discretionary: Entertainment'}\n",
    "               , {\"str\": 'papa johns', 'repl': 'Papa Johns', 'category': 'Discretionary: Entertainment'}\n",
    "               , {\"str\": 'just-eat', 'repl': 'Just Eat', 'category': 'Discretionary: Entertainment'}\n",
    "               , {\"str\": 'justeat', 'repl': 'Just Eat', 'category': 'Discretionary: Entertainment'}\n",
    "               , {\"str\": 'just eat', 'repl': 'Just Eat', 'category': 'Discretionary: Entertainment'}\n",
    "               , {\"str\": 'feast burgers', 'repl': 'Feast Burgers', 'category': 'Discretionary: Entertainment'}\n",
    "               , {\"str\": 'deliveroo', 'repl': 'Deliveroo', 'category': 'Discretionary: Entertainment'}\n",
    "               , {\"str\": 'mcdonalds', 'repl': 'McDonald''s', 'category': 'Discretionary: Entertainment'}\n",
    "               \n",
    "               , {\"str\": 'netflix', 'repl': 'Netflix', 'category': 'Monthly: Streaming'}\n",
    "               , {\"str\": 'amazonprime', 'repl': 'Amazon Prime', 'category': 'Monthly: Streaming'}\n",
    "               , {\"str\": 'amazon prime', 'repl': 'Amazon Prime', 'category': 'Monthly: Streaming'}\n",
    "               \n",
    "               , {\"str\": 'primark', 'repl': 'Primark', 'category': 'Discretionary: Misc Purchases'}\n",
    "               \n",
    "               , {\"str\": 's j p fish', 'repl': in_str, 'category': 'Basics: Rent'}\n",
    "               \n",
    "               , {\"str\": 'farrow-ball.com', 'repl': 'Farrow and ball', 'category': ''}\n",
    "               , {\"str\": 'argos', 'repl': 'Argos', 'category': ''}\n",
    "               , {\"str\": 'amazon.co.uk', 'repl': 'Amazon', 'category': ''}\n",
    "               , {\"str\": 'uber*trip', 'repl': 'Uber', 'category': ''}\n",
    "               , {\"str\": 'uber *trip', 'repl': 'Uber', 'category': ''}\n",
    "               , {\"str\": 'poundland', 'repl': 'Poundland', 'category': ''}\n",
    "               , {\"str\": 'ikea', 'repl': 'Ikea', 'category': ''}\n",
    "               , {\"str\": 'johnlewis', 'repl': 'John Lewis', 'category': ''}\n",
    "               , {\"str\": 'john lewis', 'repl': 'John Lewis', 'category': ''}\n",
    "               , {\"str\": 'independent contra emp', 'repl': 'ICS', 'category': ''}\n",
    "               , {\"str\": 'barclays', 'repl': 'Barclays', 'category': ''}\n",
    "              ]\n",
    "    for search_string in mapping:\n",
    "        if search_string['str'] in in_str.lower():\n",
    "            out_str = search_string['repl']\n",
    "            category = search_string['category']\n",
    "        \n",
    "    if 'pizza' in in_str.lower() and 'hut' in in_str.lower():\n",
    "        out_str = 'Pizza Hut'\n",
    "        category = 'Discretionary: Entertainment'\n",
    "    elif 'papa' in in_str.lower() and 'john' in in_str.lower():\n",
    "        out_str = 'Papa Johns'\n",
    "        category = 'Discretionary: Entertainment'\n",
    "        \n",
    "    return out_str, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "electronic-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ynab(df_param):\n",
    "    df_ynab = copy.deepcopy(df_param)\n",
    "    \n",
    "    # rename columns\n",
    "    df_ynab = df_ynab.rename(columns={'date': 'Date', 'payee': 'Payee'})\n",
    "    df_ynab['Date'] = pd.to_datetime(df_ynab['Date'])\n",
    "    \n",
    "    # remove balance rows\n",
    "    idx = df_ynab.loc[df_ynab['Payee'].str.contains('(?i)balance'), :].index\n",
    "    df_ynab.drop(idx, inplace=True)\n",
    "    \n",
    "    # create additional ynab columns, format values\n",
    "    df_ynab['Category'] = ''\n",
    "    df_ynab['Memo'] = ''\n",
    "    df_ynab.loc[df_ynab['amount'] < 0, 'Outflow'] = df_ynab['amount'] * -1\n",
    "    df_ynab.loc[df_ynab['amount'] > 0, 'Inflow'] = df_ynab['amount']\n",
    "    df_ynab['Outflow'].fillna('', inplace=True)\n",
    "    df_ynab['Inflow'].fillna('', inplace=True)\n",
    "    cols = ['Date', 'Payee', 'Category', 'Memo', 'Outflow', 'Inflow']\n",
    "    df_ynab = df_ynab[cols]\n",
    "    df_ynab['Date'] = df_ynab['Date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    # process payees\n",
    "    df_ynab[['Payee', 'Category']] = df_ynab['Payee'].apply(transform_payee).apply(pd.Series)\n",
    "    return df_ynab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "flying-contrary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating YNAB file for: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\3-processed\\2022-01-25_Statement_cleaned_processed.csv]\n",
      "YNAB file generated: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\4-ynab\\2022-01-25_Statement_cleaned_processed_ynab.csv]\n",
      "Generating YNAB file for: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\3-processed\\2022-02-25_Statement_cleaned_processed.csv]\n",
      "YNAB file generated: [D:\\MyDocuments\\Bank-Statements\\HSBC\\2022\\4-ynab\\2022-02-25_Statement_cleaned_processed_ynab.csv]\n"
     ]
    }
   ],
   "source": [
    "# generate ynab files\n",
    "for file in result:\n",
    "    processed_full_path = file['processed_full_path']\n",
    "    \n",
    "    print('Generating YNAB file for: [{filename}]'.format(filename=processed_full_path))\n",
    "    df_in = pd.read_csv(processed_full_path)\n",
    "    df = process_ynab(df_in)\n",
    "    file_name = os.path.basename(processed_full_path)\n",
    "    ynab_df_filename = os.path.splitext(file_name)[0] + '_ynab.csv'\n",
    "    ynab_df_full_path = os.path.join(ynab_path,ynab_df_filename)\n",
    "    \n",
    "    file['ynab_full_path'] = ynab_df_full_path\n",
    "    \n",
    "    df.to_csv(ynab_df_full_path, index=False)\n",
    "    print('YNAB file generated: [{filename}]'.format(filename=ynab_df_full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bf95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
